"""LOE Power Off integration."""
import logging
import re
from datetime import timedelta, datetime

import aiohttp
from bs4 import BeautifulSoup

from homeassistant.config_entries import ConfigEntry
from homeassistant.core import HomeAssistant
from homeassistant.helpers.update_coordinator import DataUpdateCoordinator, UpdateFailed

from .const import DOMAIN

_LOGGER = logging.getLogger(__name__)


async def async_setup_entry(hass: HomeAssistant, entry: ConfigEntry):
    """Set up LOE Power Off from a config entry."""
    url = entry.data.get("url")
    group = entry.data.get("group")

    _LOGGER.warning("Setting up LOE Power Off entry: %s, Group: %s", entry.entry_id, group)

    coordinator = ScheduleCoordinator(hass, url, group)
    await coordinator.async_config_entry_first_refresh()

    hass.data.setdefault(DOMAIN, {})[entry.entry_id] = coordinator

    hass.async_create_task(
        hass.config_entries.async_forward_entry_setups(entry, ["sensor"])
    )

    return True


class ScheduleCoordinator(DataUpdateCoordinator):
    """Coordinator to fetch LOE power off schedule."""

    def __init__(self, hass: HomeAssistant, url: str, group: str):
        super().__init__(
            hass,
            _LOGGER,
            name=f"{DOMAIN} {group}",
            update_interval=timedelta(minutes=15),
        )
        self._url = url
        self._group = group

    @staticmethod
    def _parse_intervals(text: str):
        """Convert schedule string into list of [start, end] intervals."""
        # –®—É–∫–∞—î–º–æ –≤—Å—ñ —ñ–Ω—Ç–µ—Ä–≤–∞–ª–∏ –≤–∏–¥—É "08:00 –¥–æ 12:00"
        matches = re.findall(r"(\d{2}:\d{2})\s*–¥–æ\s*(\d{2}:\d{2})", text)
        return [list(m) for m in matches]

    async def _async_update_data(self):
        """Fetch data from LOE API and parse schedule."""
        try:
            async with aiohttp.ClientSession() as session:
                async with session.get(self._url) as resp:
                    data = await resp.json()
        except Exception as err:
            _LOGGER.error("Error fetching data from LOE API: %s", err)
            raise UpdateFailed(f"Error fetching data: {err}")

        menus = [m for m in data.get("hydra:member", []) if m.get("type") == "photo-grafic"]
        if not menus:
            raise UpdateFailed("No 'photo-grafic' menu found in API response")

        latest_raw_html = None
        for menu in menus:
            for item in menu.get("menuItems", []):
                for child in item.get("children", []):
                    raw_html = child.get("rawMobileHtml") or child.get("rawHtml")
                    if raw_html:
                        latest_raw_html = raw_html

        if not latest_raw_html:
            raise UpdateFailed("No rawHtml found in any menu child")

        soup = BeautifulSoup(latest_raw_html, "html.parser")

        # –î–∞—Ç–∞ –≥—Ä–∞—Ñ—ñ–∫–∞ (—Ç—ñ–ª—å–∫–∏ –¥–∞—Ç–∞)
        day_tag = soup.find(string=lambda t: "–ì—Ä–∞—Ñ—ñ–∫ –ø–æ–≥–æ–¥–∏–Ω–Ω–∏—Ö –≤—ñ–¥–∫–ª—é—á–µ–Ω—å" in t)
        day = None
        if day_tag:
            match = re.search(r"\d{2}\.\d{2}\.\d{4}", day_tag)
            if match:
                day = match.group()

        # –ß–∞—Å –æ–Ω–æ–≤–ª–µ–Ω–Ω—è
        updated_datetime = None
        updated_tag = soup.find(string=lambda t: "–Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è —Å—Ç–∞–Ω–æ–º –Ω–∞" in t)

        if updated_tag:
            updated_text = updated_tag.strip()
            match = re.search(r"(\d{2}:\d{2})\s+(\d{2}\.\d{2}\.\d{4})", updated_text)
            if match:
                time_part = match.group(1)
                date_part = match.group(2)
                dt_string = f"{date_part} {time_part}"

                try:
                    dt_obj = datetime.strptime(dt_string, "%d.%m.%Y %H:%M")
                    updated_datetime = dt_obj.isoformat()
                except Exception as e:
                    _LOGGER.warning("Failed to parse updated datetime '%s': %s", dt_string, e)

        # –ü–∞—Ä—Å–∏–º–æ –≤—Å—ñ –≥—Ä—É–ø–∏
        schedule = {}
        for p in soup.find_all("p"):
            text = p.get_text(strip=True)
            if text.startswith("–ì—Ä—É–ø–∞"):
                split_index = text.find(".")
                if split_index != -1:
                    group_key = text[:split_index + 2].strip()
                    group_value = text[split_index + 2:].strip()
                    schedule[group_key] = group_value

        # –í–∏–±—ñ—Ä –≥—Ä—É–ø–∏
        group_schedule = None
        target_group = self._group.rstrip(".").strip()
        for key, val in schedule.items():
            normalized_key = key.rstrip(".").strip()
            if normalized_key == target_group:
                group_schedule = val
                break

        if not group_schedule:
            _LOGGER.warning("Group '%s' not found in latest graph", self._group)

        # üî• –¢–£–¢ –Ω–æ–≤–µ ‚Äî –∫–æ–Ω–≤–µ—Ä—Ç—É—î–º–æ —Ç–µ–∫—Å—Ç —É –º–∞—Å–∏–≤ —ñ–Ω—Ç–µ—Ä–≤–∞–ª—ñ–≤
        parsed_intervals = self._parse_intervals(group_schedule) if group_schedule else None

        return {
            "day": day,
            "updated": updated_datetime,
            "schedule": parsed_intervals,   # ‚Üê —Ç–µ–ø–µ—Ä —Ç—É—Ç –º–∞—Å–∏–≤ –¥–ª—è —Å—Ç–µ–π—Ç—É
            "all_groups": schedule,
        }
